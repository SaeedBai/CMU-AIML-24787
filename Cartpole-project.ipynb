{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ff7c51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./anaconda3/envs/24787/lib/python3.9/site-packages (1.21.4)\n",
      "Requirement already satisfied: gym in ./anaconda3/envs/24787/lib/python3.9/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from gym) (1.21.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from gym) (2.0.0)\n",
      "Requirement already satisfied: matplotlib in ./anaconda3/envs/24787/lib/python3.9/site-packages (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from matplotlib) (1.21.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: setuptools-scm>=4 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from matplotlib) (6.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from matplotlib) (4.28.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from setuptools-scm>=4->matplotlib) (1.2.2)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/24787/lib/python3.9/site-packages (from setuptools-scm>=4->matplotlib) (58.0.4)\n",
      "Requirement already satisfied: sklearn in ./anaconda3/envs/24787/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in ./anaconda3/envs/24787/lib/python3.9/site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.21.4)\n",
      "Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./anaconda3/envs/24787/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.7.3)\n",
      "Collecting pyglet\n",
      "  Using cached pyglet-1.5.21-py3-none-any.whl (1.1 MB)\n",
      "Installing collected packages: pyglet\n",
      "Successfully installed pyglet-1.5.21\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install gym\n",
    "!pip install matplotlib\n",
    "!pip install sklearn\n",
    "!pip install pyglet\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import gym\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d558c8f",
   "metadata": {},
   "source": [
    "## CartPole-V1 Enviornment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bdba63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282fd3c",
   "metadata": {},
   "source": [
    "## Enviornment Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f381a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "?env.env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29f38e0",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd480e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saeedbai/.local/lib/python3.8/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25917/1016165139.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#display.display(plt.gcf())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#display.clear_output(wait=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Hard coded policy value\n",
    "policy = lambda obs: 0\n",
    "for i in range(5):\n",
    "    obs = env.reset()\n",
    "    for j in range(30):\n",
    "        actions = policy(obs)\n",
    "        obs, reward, done, info = env.step(actions)\n",
    "        env.render()\n",
    "        ## IF WANT TO PRESENT ANIMATION IN JUPYTER\n",
    "        #plt.imshow(env.render(mode='rgb_array'))\n",
    "        #display.display(plt.gcf())    \n",
    "        #display.clear_output(wait=True)\n",
    "        time.sleep(0.1)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dad9971",
   "metadata": {},
   "source": [
    "## Policy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa94549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy = lambda _,__,___, tip_velocity : int( tip_velocity > 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c6a8e5",
   "metadata": {},
   "source": [
    "## Buckets and Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a58125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_bucket = (1,1,6,3)\n",
    "n_bucket = (6,12)\n",
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615b1a3",
   "metadata": {},
   "source": [
    "## Reseting boundarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e8253a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.41887903\n"
     ]
    }
   ],
   "source": [
    "state_val_bounds = list(zip(env.observation_space.low,env.observation_space.high))\n",
    "#Reset cart velocity\n",
    "state_val_bounds[1] = [-0.5,0.5]\n",
    "#Reset pole angular velocity\n",
    "state_val_bounds[3] = [-math.radians(50),math.radians(50)]\n",
    "print(state_val_bounds[2][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad735a",
   "metadata": {},
   "source": [
    "## Action index and Q value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "692ce65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 12, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_index = len(n_bucket)\n",
    "q_val_table = np.zeros(n_bucket+(n_actions,))\n",
    "q_val_table.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b09a52",
   "metadata": {},
   "source": [
    "## Define rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a56e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_exp_rate = 0.1\n",
    "min_learn_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec195af",
   "metadata": {},
   "source": [
    "## INITIALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0eea36f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 2000\n",
    "discount = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d957f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function choose what action to perform\n",
    "def sel_act(sel_val,exp_rate):\n",
    "    #epsilon greedy algorithm\n",
    "    #exploration and exploitation\n",
    "    if random.random() < exp_rate:\n",
    "        action = env.action_space.sample()\n",
    "    else:\n",
    "        action = np.argmax(q_val_table[sel_val])\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad669e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function choose what explore rate to use\n",
    "def sel_exp_rate(input):\n",
    "    return max(min_exp_rate,min(1,1.0 - math.log10((input+1)/25)))\n",
    "## This function choose what learn rate to use\n",
    "def sel_learn_rate(input):\n",
    "    return max(min_learn_rate,min(1.0,1.0 - math.log10((input+1)/25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "302f90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Discrete state value\n",
    "def discrete_state_val(stateval):\n",
    "    lower_bounds = [ env.observation_space.low[2], -math.radians(50) ]\n",
    "    upper_bounds = [ env.observation_space.high[2], math.radians(50) ]\n",
    "    est = KBinsDiscretizer(n_bins=n_bucket, encode='ordinal', strategy='uniform')\n",
    "    est.fit([lower_bounds, upper_bounds ])\n",
    "    return tuple(map(int,est.transform([[stateval[2], stateval[3]]])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3da5dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update Q value\n",
    "def update_q_val(best_q_val,reward):\n",
    "    # Temporal difference\n",
    "    return discount * best_q_val + reward\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd5a15",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6cfa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(episodes):\n",
    "    # counter for rewards earned in each episode\n",
    "    episode_reward = 0\n",
    "    \n",
    "    learn_rate = sel_learn_rate(episode)\n",
    "    exp_rate = sel_exp_rate(episode)\n",
    "    # reset enviornment\n",
    "    obs = env.reset()\n",
    "    init_state_val = discrete_state_val(obs)\n",
    "    done = False\n",
    "    \n",
    "    # each episode\n",
    "    while done == False:\n",
    "        \n",
    "        action = sel_act(init_state_val,exp_rate)\n",
    "\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        state_val = discrete_state_val(obs)\n",
    "        \n",
    "        best_q_val = np.max(q_val_table[state_val])\n",
    "        learnt_val = update_q_val(best_q_val,reward)\n",
    "        \n",
    "        old_val = q_val_table[init_state_val][action]\n",
    "        \n",
    "        # Bellman equation\n",
    "        q_val_table[init_state_val][action] = (1 - learn_rate) * old_val + learnt_val * learn_rate\n",
    "\n",
    "        init_state_val = state_val\n",
    "        env.render()\n",
    "    \n",
    "        episode_reward += reward\n",
    "        \n",
    "    print(episode_reward)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65a143a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "render() got an unexpected keyword argument 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13849/406053282.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/24787/lib/python3.9/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"human\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: render() got an unexpected keyword argument 'close'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c0936b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752e713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d7ac82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
